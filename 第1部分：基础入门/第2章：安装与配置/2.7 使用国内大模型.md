# 2.7 使用国内大模型

## 2.7.1 概述

随着国内大模型技术的快速发展，越来越多的国内大模型平台推出了Coding Plan，支持Claude Code的接入和使用。这些国内大模型通常具有更低的使用成本和更好的本地化支持，为用户提供了更多选择。本节将介绍如何在Claude Code中使用国内大模型，包括支持的平台和配置方法。

## 2.7.2 支持的国内大模型

目前，以下国内大模型平台支持Claude Code的接入和使用：

### 2.7.2.1 GLM

- **Coding Plan**：提供专门的编程模型GLM-4.6，据称能使用户仅用1/7的价格即享受到接近Claude Sonnet 4的代码能力
- **特点**：支持多语言代码生成、代码审查、调试等功能，具有良好的中文理解能力
- **接入方式**：通过API密钥接入，支持Claude Code的所有核心功能

### 2.7.2.2 通义千问 (Qwen)

- **Coding Plan**：提供Qwen3-Coder-Plus模型，专门针对编程场景优化
- **特点**：支持代码生成、代码补全、代码解释等功能，在中文编程场景中表现优异
- **接入方式**：通过百炼平台获取API密钥，支持Claude Code无缝对接

### 2.7.2.3 DeepSeek

- **Coding Plan**：提供DeepSeek V3模型，专注于代码生成和理解
- **特点**：在代码生成速度和准确性方面表现出色，支持多种编程语言
- **接入方式**：通过官方API平台获取密钥，支持Claude Code集成

### 2.7.2.4 豆包 (Doubao)

- **Coding Plan**：推出国内首个支持视觉理解能力的编程模型
- **特点**：支持代码生成、代码审查、文档生成等功能，具有良好的用户体验
- **接入方式**：通过字节跳动开放平台获取API密钥，支持Claude Code接入

### 2.7.2.5 Kimi

- **Coding Plan**：提供Kimi 2模型，支持代码生成和理解
- **特点**：在长上下文代码理解方面表现出色，支持大型代码库分析
- **接入方式**：通过官方平台获取API密钥，支持Claude Code集成

## 2.7.3 配置方法

### 2.7.3.1 准备工作

1. 注册并登录所选国内大模型平台的账号
2. 开通Coding Plan或编程模型服务
3. 获取API密钥和API端点信息
4. 确保已安装最新版本的Claude Code

### 2.7.3.2 在VS Code中配置

1. 打开VS Code
2. 点击左侧边栏的**Claude Code**图标
3. 点击右上角的**设置**按钮（齿轮图标）
4. 选择**模型设置**
5. 选择**自定义模型**
6. 输入以下信息：
   - 模型名称：自定义名称（如"GLM-4.6"）
   - API端点：国内大模型平台提供的API地址
   - API密钥：你的API密钥
   - 模型类型：选择适合的模型类型
7. 点击**保存**按钮

### 2.7.3.3 在命令行中配置

1. 打开终端或命令提示符
2. 运行以下命令配置自定义模型：
   ```bash
   claude config set custom-model "{\
  \"name\": \"GLM-4.6\",\
  \"endpoint\": \"https://api.example.com/v1/chat/completions\",\
  \"api_key\": \"your-api-key-here\",\
  \"model_type\": \"code\"\
}"
   ```
3. 设置默认使用的模型：
   ```bash
   claude config set model custom:GLM-4.6
   ```

### 2.7.3.4 直接修改配置文件

除了上述方法外，您还可以直接编辑Claude Code的配置文件来设置国内大模型。

#### 2.7.3.4.1 配置文件位置

Claude Code的配置文件位于用户目录下的`.claude/settings.json`文件中：

- Windows: `C:\Users\YourUsername\.claude\settings.json`
- macOS/Linux: `~/.claude/settings.json`

如果该文件不存在，可以手动创建。

#### 2.7.3.4.2 配置文件格式

使用文本编辑器打开`settings.json`文件，并添加以下配置：

```json
{
  "env": {
    "ANTHROPIC_BASE_URL": "https://api.example.com/v1",
    "ANTHROPIC_AUTH_TOKEN": "your-api-key-here"
  },
  "model": "glm-4.6",
  "custom-model": {
    "name": "GLM-4.6",
    "endpoint": "https://api.example.com/v1/chat/completions",
    "api_key": "your-api-key-here",
    "model_type": "code"
  }
}
```

#### 2.7.3.4.3 配置说明

- **env.ANTHROPIC_BASE_URL**: 国内大模型的API端点URL
- **env.ANTHROPIC_AUTH_TOKEN**: 您的API密钥
- **model**: 默认使用的模型名称
- **custom-model**: 自定义模型配置
  - **name**: 模型名称（自定义）
  - **endpoint**: API端点URL
  - **api_key**: API密钥
  - **model_type**: 模型类型（通常为"code"）

#### 2.7.3.4.4 示例：配置GLM

```json
{
  "env": {
    "ANTHROPIC_BASE_URL": "https://open.bigmodel.cn/api/paas/v4",
    "ANTHROPIC_AUTH_TOKEN": "your-glm-api-key"
  },
  "model": "glm-4.6",
  "custom-model": {
    "name": "GLM-4.6",
    "endpoint": "https://open.bigmodel.cn/api/paas/v4/chat/completions",
    "api_key": "your-glm-api-key",
    "model_type": "code"
  }
}
```

保存配置文件后，重启Claude Code或VS Code插件使配置生效。

## 2.7.4 注意事项

1. **API兼容性**：确保所选国内大模型的API与Claude Code兼容
2. **成本控制**：国内大模型通常提供更优惠的价格，但仍需注意使用量和成本控制
3. **功能差异**：不同大模型在功能和性能上可能存在差异，建议根据实际需求选择
4. **数据隐私**：使用国内大模型时，注意数据隐私和安全保护
5. **更新维护**：定期关注国内大模型平台的更新和维护信息